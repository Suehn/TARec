2024-10-15 02:15: PID: 309256

2024-10-15 02:15: args: 
name                              : MMTA_KD
dataset                           : amazon
data_path                         : /home/ZIYIAP/Documents/OneDrive_local/distiller/TARec/data
Ks                                : [10, 20, 40, 50]
seed                              : 14322
sparse                            : 1
test_flag                         : part
edge_mask                         : 0
edge_mask_rate                    : 0.1
batch_size                        : 4096
epoch                             : 1000
cf_model                          : light_init
early_stopping_patience           : 12
gpu_id                            : 0
regs                              : [1e-5,1e-5,1e-2]
emb_reg                           : 1e-07
teacher_model_type                : gcl
lr                                : 0.0004
teacher_model_dict_name           : teacher_model_great
teacher_reg_rate                  : 1
t_weight_decay                    : 0.001
t_feat_mf_rate                    : 0.001
feat_reg_decay                    : 1e-05
is_softmax                        : False
is_gcl_softmax                    : False
teacher_assistant_model_type      : lightgcl
teacher_assistant_model_dict_name : teacher_assistant_model_great
student_model_type                : mlpgcl
student_model_dict_name           : 
student_embed_size                : 64
student_lr                        : 0.001
student_reg_rate                  : 1
student_drop_rate                 : 0.2
student_tau                       : 5
embed_size                        : 64
drop_rate                         : 0.4
weight_size                       : [64, 64]
model_cat_rate                    : 0.028
layers                            : 1
n_layers                          : 2
ta_n_layers                       : 1
student_n_layers                  : 1
mlp_n_layers                      : 1
if_train_teacher                  : True
is_train_student                  : False
kd_loss_rate                      : 5e-06
kd_loss_feat_rate                 : 0.1
cl_loss_rate                      : 0.002
svd_gcl_rate                      : 0.0
x_gcl_rate                        : 0.25
layer_gcl                         : 1.0
svd_layer_gcl                     : 0.0
xsvd_gcl                          : 0.0
x_layer_gcl                       : 0.0
ssm_rate                          : 0.5
s_layer_gcl                       : 0.0025
t_cl_loss_rate                    : 0.004
hard_token_type                   : pca
soft_token_rate                   : 0.1
feat_soft_token_rate              : 9
t_prompt_rate1                    : 100.0
prompt_dropout                    : 0
alpha_l                           : 2
feat_loss_type                    : sce
neg_sample_num                    : 10
list_wise_loss_rate               : 1
q                                 : 1
eps                               : 0.2
kd_t_decay_threshold              : 0.0
kd_ta_decay_rate                  : 0.6
kd_t_decay_rate                   : 0.6
t_init_method                     : uniform
norm_mode                         : None
ta_norm_mode                      : None
s_norm_mode                       : None
s_norm_scale                      : 0.05
ta_norm_scale                     : 0.0
norm_scale                        : 0.08
kd_loss_type                      : sinkhorn
is_teacher_kd                     : False
init_teacher                      : False
t_bpr_loss_rate                   : 1.0
2024-10-15 02:15: ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸
2024-10-15 02:15: ðŸŽ“ðŸ“˜ Start training teacher model... ðŸš€âœ¨
2024-10-15 02:15: Teacher model type: gcl
2024-10-15 02:15: ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸ðŸ”¸

2024-10-15 02:16: ðŸŽ‰Best recall: [0.01617, 0.02593, 0.04505, 0.05164], Best ndcg: [0.00836, 0.01081, 0.01469, 0.01588]. Model saved to teacher_model_great.pt
2024-10-15 02:16: ðŸŽ“ðŸ“˜Epoch 1/1000 Early stopping 0 - Recall 0.02593, Ndcg: 0.0108 || Avg Loss: 450.7372 | BPR: 0.3468, Prompt: 4.4993, Image: 7.5680, Text: 0.5662, Reg: 0.0003, Feat_Reg: 0.0099, GCL: 0.4422
2024-10-15 02:16: ðŸŽ“ðŸ“˜Epoch 2/1000 Early stopping 1 - Recall 0.03296, Ndcg: 0.0135 || Avg Loss: 75.6812 | BPR: 0.2263, Prompt: 0.7508, Image: 0.3922, Text: 0.1469, Reg: 0.0004, Feat_Reg: 0.0038, GCL: 0.3698
2024-10-15 02:16: ðŸŽ“ðŸ“˜Epoch 3/1000 Early stopping 2 - Recall 0.03718, Ndcg: 0.0155 || Avg Loss: 39.7834 | BPR: 0.1629, Prompt: 0.3927, Image: 0.2852, Text: 0.1395, Reg: 0.0004, Feat_Reg: 0.0030, GCL: 0.3512
2024-10-15 02:17: ðŸŽ“ðŸ“˜Epoch 4/1000 Early stopping 3 - Recall 0.03835, Ndcg: 0.0160 || Avg Loss: 27.5640 | BPR: 0.1191, Prompt: 0.2710, Image: 0.2361, Text: 0.1328, Reg: 0.0005, Feat_Reg: 0.0025, GCL: 0.3419
2024-10-15 02:17: ðŸŽ“ðŸ“˜Epoch 5/1000 Early stopping 4 - Recall 0.04034, Ndcg: 0.0167 || Avg Loss: 21.0459 | BPR: 0.0881, Prompt: 0.2062, Image: 0.2056, Text: 0.1297, Reg: 0.0006, Feat_Reg: 0.0022, GCL: 0.3366
2024-10-15 02:17: ðŸŽ“ðŸ“˜Epoch 6/1000 Early stopping 5 - Recall 0.04080, Ndcg: 0.0168 || Avg Loss: 17.7342 | BPR: 0.0685, Prompt: 0.1733, Image: 0.1873, Text: 0.1294, Reg: 0.0006, Feat_Reg: 0.0020, GCL: 0.3333
2024-10-15 02:18: ðŸŽ“ðŸ“˜Epoch 7/1000 Early stopping 6 - Recall 0.03965, Ndcg: 0.0163 || Avg Loss: 15.6648 | BPR: 0.0534, Prompt: 0.1528, Image: 0.1699, Text: 0.1302, Reg: 0.0007, Feat_Reg: 0.0018, GCL: 0.3312
2024-10-15 02:18: ðŸŽ“ðŸ“˜Epoch 8/1000 Early stopping 7 - Recall 0.03977, Ndcg: 0.0164 || Avg Loss: 14.5782 | BPR: 0.0435, Prompt: 0.1420, Image: 0.1565, Text: 0.1275, Reg: 0.0007, Feat_Reg: 0.0017, GCL: 0.3297
2024-10-15 02:18: ðŸŽ‰Best recall: [0.02511, 0.04013, 0.06155, 0.06942], Best ndcg: [0.01289, 0.01665, 0.02103, 0.02245]. Model saved to teacher_model_great.pt
2024-10-15 02:18: ðŸŽ“ðŸ“˜Epoch 9/1000 Early stopping 0 - Recall 0.04013, Ndcg: 0.0167 || Avg Loss: 14.0035 | BPR: 0.0366, Prompt: 0.1364, Image: 0.1495, Text: 0.1271, Reg: 0.0007, Feat_Reg: 0.0016, GCL: 0.3287
2024-10-15 02:19: ðŸŽ“ðŸ“˜Epoch 10/1000 Early stopping 1 - Recall 0.03915, Ndcg: 0.0162 || Avg Loss: 13.8808 | BPR: 0.0310, Prompt: 0.1352, Image: 0.1453, Text: 0.1266, Reg: 0.0008, Feat_Reg: 0.0014, GCL: 0.3278
2024-10-15 02:19: ðŸŽ“ðŸ“˜Epoch 11/1000 Early stopping 2 - Recall 0.03974, Ndcg: 0.0165 || Avg Loss: 13.4446 | BPR: 0.0270, Prompt: 0.1309, Image: 0.1271, Text: 0.1251, Reg: 0.0008, Feat_Reg: 0.0014, GCL: 0.3273
2024-10-15 02:19: ðŸŽ“ðŸ“˜Epoch 12/1000 Early stopping 3 - Recall 0.03991, Ndcg: 0.0165 || Avg Loss: 13.6040 | BPR: 0.0239, Prompt: 0.1325, Image: 0.1200, Text: 0.1270, Reg: 0.0008, Feat_Reg: 0.0013, GCL: 0.3269
2024-10-15 02:20: ðŸŽ“ðŸ“˜Epoch 13/1000 Early stopping 4 - Recall 0.03946, Ndcg: 0.0163 || Avg Loss: 13.2400 | BPR: 0.0215, Prompt: 0.1289, Image: 0.1101, Text: 0.1248, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3264
2024-10-15 02:20: ðŸŽ“ðŸ“˜Epoch 14/1000 Early stopping 5 - Recall 0.03835, Ndcg: 0.0157 || Avg Loss: 13.3166 | BPR: 0.0193, Prompt: 0.1297, Image: 0.1185, Text: 0.1241, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3262
2024-10-15 02:20: ðŸŽ“ðŸ“˜Epoch 15/1000 Early stopping 6 - Recall 0.03835, Ndcg: 0.0158 || Avg Loss: 12.9866 | BPR: 0.0183, Prompt: 0.1264, Image: 0.1260, Text: 0.1244, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3260
2024-10-15 02:21: ðŸŽ“ðŸ“˜Epoch 16/1000 Early stopping 7 - Recall 0.03833, Ndcg: 0.0160 || Avg Loss: 12.8454 | BPR: 0.0163, Prompt: 0.1250, Image: 0.1098, Text: 0.1227, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3258
2024-10-15 02:21: ðŸŽ“ðŸ“˜Epoch 17/1000 Early stopping 8 - Recall 0.03663, Ndcg: 0.0152 || Avg Loss: 12.8900 | BPR: 0.0153, Prompt: 0.1255, Image: 0.3523, Text: 0.1229, Reg: 0.0009, Feat_Reg: 0.0012, GCL: 0.3256
2024-10-15 02:21: ðŸŽ“ðŸ“˜Epoch 18/1000 Early stopping 9 - Recall 0.03631, Ndcg: 0.0150 || Avg Loss: 12.8173 | BPR: 0.0147, Prompt: 0.1247, Image: 0.5391, Text: 0.1223, Reg: 0.0009, Feat_Reg: 0.0014, GCL: 0.3255
