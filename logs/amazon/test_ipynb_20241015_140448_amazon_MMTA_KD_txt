2024-10-15 14:04: PID: 2915

2024-10-15 14:04: args: 
name                              : MMTA_KD
dataset                           : amazon
data_path                         : /home/ZIYIAP/Documents/OneDrive_local/distiller/TARec/data
Ks                                : [10, 20, 40, 50]
seed                              : 14322
sparse                            : 1
test_flag                         : part
edge_mask                         : 0
edge_mask_rate                    : 0.1
batch_size                        : 4096
epoch                             : 1000
cf_model                          : light_init
early_stopping_patience           : 8
gpu_id                            : 0
regs                              : [1e-5,1e-5,1e-2]
emb_reg                           : 1e-07
teacher_model_type                : gcl
lr                                : 0.0003
teacher_model_dict_name           : teacher_model_great
teacher_reg_rate                  : 1
t_weight_decay                    : 0.001
t_feat_mf_rate                    : 0.001
feat_reg_decay                    : 1e-05
is_softmax                        : False
is_gcl_softmax                    : False
teacher_assistant_model_type      : lightgcl
teacher_assistant_model_dict_name : teacher_assistant_model_great
student_model_type                : mlpgcl
student_model_dict_name           : 
student_embed_size                : 64
student_lr                        : 0.001
student_reg_rate                  : 1
student_drop_rate                 : 0.2
student_tau                       : 5
embed_size                        : 64
drop_rate                         : 0.4
weight_size                       : [64, 64]
model_cat_rate                    : 0.028
layers                            : 1
n_layers                          : 2
ta_n_layers                       : 1
student_n_layers                  : 1
mlp_n_layers                      : 1
if_train_teacher                  : True
is_train_student                  : False
kd_loss_rate                      : 5e-06
kd_loss_feat_rate                 : 0.1
cl_loss_rate                      : 0.002
svd_gcl_rate                      : 0.0
x_gcl_rate                        : 0.25
layer_gcl                         : 1.0
svd_layer_gcl                     : 0.0
xsvd_gcl                          : 0.0
x_layer_gcl                       : 0.0
ssm_rate                          : 0.5
s_layer_gcl                       : 0.0025
t_cl_loss_rate                    : 0.004
hard_token_type                   : pca
soft_token_rate                   : 0.1
feat_soft_token_rate              : 9
t_prompt_rate1                    : 100.0
prompt_dropout                    : 0
alpha_l                           : 2
feat_loss_type                    : sce
neg_sample_num                    : 10
list_wise_loss_rate               : 1
q                                 : 1
eps                               : 0.2
kd_t_decay_threshold              : 0.0
kd_ta_decay_rate                  : 0.6
kd_t_decay_rate                   : 0.6
t_init_method                     : uniform
norm_mode                         : None
ta_norm_mode                      : None
s_norm_mode                       : None
s_norm_scale                      : 0.05
ta_norm_scale                     : 0.0
norm_scale                        : 0.08
kd_loss_type                      : sinkhorn
is_teacher_kd                     : False
init_teacher                      : False
t_bpr_loss_rate                   : 1.0
2024-10-15 14:04: ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸
2024-10-15 14:04: ğŸ“ğŸ“˜ Start training teacher model... ğŸš€âœ¨
2024-10-15 14:04: Teacher model type: gcl
2024-10-15 14:04: ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸

2024-10-15 14:06: ğŸ“ğŸ“˜Epoch 1/1000 Early stopping 0 - Recall 0.02545, Ndcg: 0.0108 || Avg Loss: 556.3646 | BPR: 0.3667, Prompt: 5.5552, Image: 5.1447, Text: 0.6405, Reg: 0.0003, Feat_Reg: 0.0088, GCL: 0.4580
2024-10-15 14:06: ğŸ“ğŸ“˜Epoch 2/1000 Early stopping 0 - Recall 0.03087, Ndcg: 0.0126 || Avg Loss: 106.3733 | BPR: 0.2553, Prompt: 1.0573, Image: 0.3695, Text: 0.1556, Reg: 0.0003, Feat_Reg: 0.0038, GCL: 0.3796
2024-10-15 14:06: ğŸ“ğŸ“˜Epoch 3/1000 Early stopping 0 - Recall 0.03416, Ndcg: 0.0138 || Avg Loss: 54.4545 | BPR: 0.1969, Prompt: 0.5389, Image: 0.2868, Text: 0.1399, Reg: 0.0004, Feat_Reg: 0.0030, GCL: 0.3591
2024-10-15 14:07: ğŸ“ğŸ“˜Epoch 4/1000 Early stopping 0 - Recall 0.03615, Ndcg: 0.0150 || Avg Loss: 36.2729 | BPR: 0.1553, Prompt: 0.3577, Image: 0.2367, Text: 0.1388, Reg: 0.0004, Feat_Reg: 0.0026, GCL: 0.3479
2024-10-15 14:07: ğŸ“ğŸ“˜Epoch 5/1000 Early stopping 0 - Recall 0.03855, Ndcg: 0.0159 || Avg Loss: 27.3479 | BPR: 0.1215, Prompt: 0.2688, Image: 0.2174, Text: 0.1328, Reg: 0.0005, Feat_Reg: 0.0023, GCL: 0.3412
2024-10-15 14:08: ğŸ“ğŸ“˜Epoch 6/1000 Early stopping 0 - Recall 0.03903, Ndcg: 0.0161 || Avg Loss: 21.9379 | BPR: 0.0973, Prompt: 0.2150, Image: 0.2051, Text: 0.1321, Reg: 0.0005, Feat_Reg: 0.0020, GCL: 0.3367
2024-10-15 14:08: ğŸ“ğŸ“˜Epoch 7/1000 Early stopping 0 - Recall 0.03986, Ndcg: 0.0165 || Avg Loss: 18.5979 | BPR: 0.0790, Prompt: 0.1818, Image: 0.1725, Text: 0.1313, Reg: 0.0006, Feat_Reg: 0.0018, GCL: 0.3340
2024-10-15 14:08: ğŸ“ğŸ“˜Epoch 8/1000 Early stopping 0 - Recall 0.03970, Ndcg: 0.0165 || Avg Loss: 16.2445 | BPR: 0.0639, Prompt: 0.1585, Image: 0.1450, Text: 0.1293, Reg: 0.0006, Feat_Reg: 0.0017, GCL: 0.3319
2024-10-15 14:09: ğŸ‰Best recall: [0.02459, 0.03941, 0.06232, 0.07037], Best ndcg: [0.01277, 0.01650, 0.02117, 0.02262]. Model saved to teacher_model_great.pt
2024-10-15 14:09: ğŸ“ğŸ“˜Epoch 9/1000 Early stopping 0 - Recall 0.03941, Ndcg: 0.0165 || Avg Loss: 15.5050 | BPR: 0.0536, Prompt: 0.1512, Image: 0.1396, Text: 0.1291, Reg: 0.0007, Feat_Reg: 0.0016, GCL: 0.3304
2024-10-15 14:09: ğŸ‰Best recall: [0.02552, 0.04061, 0.06304, 0.07107], Best ndcg: [0.01325, 0.01704, 0.02161, 0.02307]. Model saved to teacher_model_great.pt
2024-10-15 14:09: ğŸ“ğŸ“˜Epoch 10/1000 Early stopping 0 - Recall 0.04061, Ndcg: 0.0170 || Avg Loss: 14.5629 | BPR: 0.0463, Prompt: 0.1419, Image: 0.1367, Text: 0.1294, Reg: 0.0007, Feat_Reg: 0.0015, GCL: 0.3292
2024-10-15 14:10: ğŸ“ğŸ“˜Epoch 11/1000 Early stopping 1 - Recall 0.04058, Ndcg: 0.0170 || Avg Loss: 14.0967 | BPR: 0.0392, Prompt: 0.1373, Image: 0.1305, Text: 0.1268, Reg: 0.0007, Feat_Reg: 0.0014, GCL: 0.3284
2024-10-15 14:10: ğŸ“ğŸ“˜Epoch 12/1000 Early stopping 2 - Recall 0.04032, Ndcg: 0.0169 || Avg Loss: 13.4712 | BPR: 0.0350, Prompt: 0.1311, Image: 0.1218, Text: 0.1275, Reg: 0.0007, Feat_Reg: 0.0013, GCL: 0.3277
2024-10-15 14:10: ğŸ“ğŸ“˜Epoch 13/1000 Early stopping 3 - Recall 0.04010, Ndcg: 0.0168 || Avg Loss: 13.3600 | BPR: 0.0317, Prompt: 0.1300, Image: 0.1250, Text: 0.1260, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3271
2024-10-15 14:11: ğŸ“ğŸ“˜Epoch 14/1000 Early stopping 4 - Recall 0.03864, Ndcg: 0.0160 || Avg Loss: 13.1260 | BPR: 0.0276, Prompt: 0.1277, Image: 0.1356, Text: 0.1270, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3267
2024-10-15 14:11: ğŸ“ğŸ“˜Epoch 15/1000 Early stopping 5 - Recall 0.03886, Ndcg: 0.0162 || Avg Loss: 12.9057 | BPR: 0.0247, Prompt: 0.1255, Image: 0.1157, Text: 0.1254, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3265
2024-10-15 14:11: ğŸ“ğŸ“˜Epoch 16/1000 Early stopping 6 - Recall 0.03946, Ndcg: 0.0164 || Avg Loss: 13.0298 | BPR: 0.0233, Prompt: 0.1268, Image: 0.1066, Text: 0.1253, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3260
2024-10-15 14:12: ğŸ“ğŸ“˜Epoch 17/1000 Early stopping 7 - Recall 0.03900, Ndcg: 0.0162 || Avg Loss: 12.7397 | BPR: 0.0213, Prompt: 0.1239, Image: 0.1109, Text: 0.1240, Reg: 0.0008, Feat_Reg: 0.0010, GCL: 0.3257
2024-10-15 14:12: early stopping at epoch 18
2024-10-15 14:12: ğŸ†ğŸ‰Final model saved to /home/ZIYIAP/Documents/OneDrive_local/distiller/TARec/Model/teacher/amazon/teacher_model_final.pt, best epoch: 10, best recall: [0.02552, 0.04061, 0.06304, 0.07107], best ndcg: [0.01325, 0.01704, 0.02161, 0.02307]
2024-10-15 14:12: â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
2024-10-15 14:12: âœ…ğŸ“ğŸ“˜ Finished training teacher model... ğŸ†ğŸ‰
2024-10-15 14:12: â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
