2024-10-15 15:34: PID: 24378

2024-10-15 15:34: args: 
name                              : MMTA_KD
dataset                           : amazon
data_path                         : /home/ZIYIAP/Documents/OneDrive_local/distiller/TARec/data
Ks                                : [10, 20, 40, 50]
seed                              : 14322
sparse                            : 1
test_flag                         : part
edge_mask                         : 0
edge_mask_rate                    : 0.1
batch_size                        : 4096
epoch                             : 1000
cf_model                          : light_init
early_stopping_patience           : 8
gpu_id                            : 0
regs                              : [1e-5,1e-5,1e-2]
emb_reg                           : 1e-07
teacher_model_type                : gcl
lr                                : 0.0003
teacher_model_dict_name           : teacher_model_great
teacher_reg_rate                  : 1
t_weight_decay                    : 0.001
t_feat_mf_rate                    : 0.001
feat_reg_decay                    : 1e-05
is_softmax                        : False
is_gcl_softmax                    : False
teacher_assistant_model_type      : lightgcl
teacher_assistant_model_dict_name : teacher_assistant_model_great
student_model_type                : mlpgcl
student_model_dict_name           : 
student_embed_size                : 64
student_lr                        : 0.001
student_reg_rate                  : 1
student_drop_rate                 : 0.2
student_tau                       : 5
embed_size                        : 64
drop_rate                         : 0.4
weight_size                       : [64, 64]
model_cat_rate                    : 0.028
layers                            : 1
n_layers                          : 2
ta_n_layers                       : 1
student_n_layers                  : 1
mlp_n_layers                      : 1
if_train_teacher                  : True
is_train_student                  : False
kd_loss_rate                      : 5e-06
kd_loss_feat_rate                 : 0.1
cl_loss_rate                      : 0.002
svd_gcl_rate                      : 0.0
x_gcl_rate                        : 0.25
layer_gcl                         : 1.0
svd_layer_gcl                     : 0.0
xsvd_gcl                          : 0.0
x_layer_gcl                       : 0.0
ssm_rate                          : 0.5
s_layer_gcl                       : 0.0025
t_cl_loss_rate                    : 0.004
hard_token_type                   : pca
soft_token_rate                   : 0.1
feat_soft_token_rate              : 9
t_prompt_rate1                    : 100.0
prompt_dropout                    : 0
alpha_l                           : 2
feat_loss_type                    : sce
neg_sample_num                    : 10
list_wise_loss_rate               : 1
q                                 : 1
eps                               : 0.2
kd_t_decay_threshold              : 0.0
kd_ta_decay_rate                  : 0.6
kd_t_decay_rate                   : 0.6
t_init_method                     : uniform
norm_mode                         : None
ta_norm_mode                      : None
s_norm_mode                       : None
s_norm_scale                      : 0.05
ta_norm_scale                     : 0.0
norm_scale                        : 0.08
kd_loss_type                      : sinkhorn
is_teacher_kd                     : False
init_teacher                      : False
t_bpr_loss_rate                   : 1.0
2024-10-15 15:34: ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸
2024-10-15 15:34: ğŸ“ğŸ“˜ Start training teacher model... ğŸš€âœ¨
2024-10-15 15:34: Teacher model type: gcl
2024-10-15 15:34: ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸

2024-10-15 15:34: ğŸ“ğŸ“˜Epoch 1/1000 Early stopping 0 - Recall 0.02569, Ndcg: 0.0107 || Avg Loss: 555.4485 | BPR: 0.3662, Prompt: 5.5461, Image: 5.0365, Text: 0.6393, Reg: 0.0003, Feat_Reg: 0.0088, GCL: 0.4579
2024-10-15 15:35: ğŸ“ğŸ“˜Epoch 2/1000 Early stopping 0 - Recall 0.03065, Ndcg: 0.0125 || Avg Loss: 107.2247 | BPR: 0.2551, Prompt: 1.0659, Image: 0.3846, Text: 0.1523, Reg: 0.0004, Feat_Reg: 0.0037, GCL: 0.3796
2024-10-15 15:35: ğŸ“ğŸ“˜Epoch 3/1000 Early stopping 0 - Recall 0.03512, Ndcg: 0.0143 || Avg Loss: 54.3486 | BPR: 0.1966, Prompt: 0.5379, Image: 0.2790, Text: 0.1387, Reg: 0.0004, Feat_Reg: 0.0030, GCL: 0.3590
2024-10-15 15:36: ğŸ“ğŸ“˜Epoch 4/1000 Early stopping 0 - Recall 0.03715, Ndcg: 0.0155 || Avg Loss: 36.4939 | BPR: 0.1548, Prompt: 0.3599, Image: 0.2423, Text: 0.1355, Reg: 0.0004, Feat_Reg: 0.0025, GCL: 0.3478
2024-10-15 15:36: ğŸ“ğŸ“˜Epoch 5/1000 Early stopping 0 - Recall 0.03874, Ndcg: 0.0160 || Avg Loss: 26.9870 | BPR: 0.1209, Prompt: 0.2652, Image: 0.2145, Text: 0.1338, Reg: 0.0005, Feat_Reg: 0.0022, GCL: 0.3411
2024-10-15 15:36: ğŸ“ğŸ“˜Epoch 6/1000 Early stopping 0 - Recall 0.03900, Ndcg: 0.0163 || Avg Loss: 21.8337 | BPR: 0.0965, Prompt: 0.2140, Image: 0.1946, Text: 0.1322, Reg: 0.0005, Feat_Reg: 0.0020, GCL: 0.3369
2024-10-15 15:37: ğŸ“ğŸ“˜Epoch 7/1000 Early stopping 0 - Recall 0.03943, Ndcg: 0.0165 || Avg Loss: 18.5759 | BPR: 0.0777, Prompt: 0.1816, Image: 0.1807, Text: 0.1320, Reg: 0.0006, Feat_Reg: 0.0018, GCL: 0.3339
2024-10-15 15:37: ğŸ“ğŸ“˜Epoch 8/1000 Early stopping 0 - Recall 0.03996, Ndcg: 0.0167 || Avg Loss: 16.2510 | BPR: 0.0643, Prompt: 0.1585, Image: 0.1527, Text: 0.1303, Reg: 0.0006, Feat_Reg: 0.0017, GCL: 0.3318
2024-10-15 15:38: ğŸ‰Best recall: [0.02451, 0.03979, 0.06138, 0.06889], Best ndcg: [0.01268, 0.01652, 0.02093, 0.02229]. Model saved to teacher_model_great.pt
2024-10-15 15:38: ğŸ“ğŸ“˜Epoch 9/1000 Early stopping 0 - Recall 0.03979, Ndcg: 0.0165 || Avg Loss: 15.1596 | BPR: 0.0538, Prompt: 0.1477, Image: 0.1480, Text: 0.1299, Reg: 0.0007, Feat_Reg: 0.0016, GCL: 0.3304
2024-10-15 15:38: ğŸ‰Best recall: [0.02543, 0.04082, 0.06220, 0.07033], Best ndcg: [0.01312, 0.01697, 0.02135, 0.02282]. Model saved to teacher_model_great.pt
2024-10-15 15:38: ğŸ“ğŸ“˜Epoch 10/1000 Early stopping 0 - Recall 0.04082, Ndcg: 0.0170 || Avg Loss: 14.5429 | BPR: 0.0460, Prompt: 0.1417, Image: 0.1363, Text: 0.1281, Reg: 0.0007, Feat_Reg: 0.0015, GCL: 0.3292
2024-10-15 15:38: ğŸ“ğŸ“˜Epoch 11/1000 Early stopping 1 - Recall 0.04037, Ndcg: 0.0168 || Avg Loss: 13.7958 | BPR: 0.0396, Prompt: 0.1343, Image: 0.1306, Text: 0.1290, Reg: 0.0007, Feat_Reg: 0.0014, GCL: 0.3283
2024-10-15 15:39: ğŸ“ğŸ“˜Epoch 12/1000 Early stopping 2 - Recall 0.04018, Ndcg: 0.0169 || Avg Loss: 13.5416 | BPR: 0.0349, Prompt: 0.1318, Image: 0.1258, Text: 0.1280, Reg: 0.0007, Feat_Reg: 0.0013, GCL: 0.3277
2024-10-15 15:39: ğŸ“ğŸ“˜Epoch 13/1000 Early stopping 3 - Recall 0.03986, Ndcg: 0.0166 || Avg Loss: 13.3809 | BPR: 0.0314, Prompt: 0.1302, Image: 0.1237, Text: 0.1265, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3272
2024-10-15 15:40: ğŸ“ğŸ“˜Epoch 14/1000 Early stopping 4 - Recall 0.03938, Ndcg: 0.0163 || Avg Loss: 13.1020 | BPR: 0.0284, Prompt: 0.1274, Image: 0.1179, Text: 0.1271, Reg: 0.0008, Feat_Reg: 0.0012, GCL: 0.3267
2024-10-15 15:40: ğŸ“ğŸ“˜Epoch 15/1000 Early stopping 5 - Recall 0.03946, Ndcg: 0.0163 || Avg Loss: 13.0252 | BPR: 0.0254, Prompt: 0.1267, Image: 0.1098, Text: 0.1256, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3265
2024-10-15 15:40: ğŸ“ğŸ“˜Epoch 16/1000 Early stopping 6 - Recall 0.03912, Ndcg: 0.0163 || Avg Loss: 12.9814 | BPR: 0.0228, Prompt: 0.1263, Image: 0.1116, Text: 0.1264, Reg: 0.0008, Feat_Reg: 0.0011, GCL: 0.3261
2024-10-15 15:41: ğŸ“ğŸ“˜Epoch 17/1000 Early stopping 7 - Recall 0.03881, Ndcg: 0.0162 || Avg Loss: 12.7747 | BPR: 0.0210, Prompt: 0.1242, Image: 0.9164, Text: 0.1254, Reg: 0.0008, Feat_Reg: 0.0016, GCL: 0.3258
2024-10-15 15:41: early stopping at epoch 18
2024-10-15 15:41: ğŸ†ğŸ‰Final model saved to /home/ZIYIAP/Documents/OneDrive_local/distiller/TARec/Model/teacher/amazon/teacher_model_final.pt, best epoch: 10, best recall: [0.02543, 0.04082, 0.06220, 0.07033], best ndcg: [0.01312, 0.01697, 0.02135, 0.02282]
2024-10-15 15:41: â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
2024-10-15 15:41: âœ…ğŸ“ğŸ“˜ Finished training teacher model... ğŸ†ğŸ‰
2024-10-15 15:41: â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
